# 1724检查边长度限制的路径是否存在 II
<p>一张有 <code>n</code> 个节点的无向图以边的列表 <code>edgeList</code> 的形式定义，其中 <code>edgeList[i] = [u<sub>i</sub>, v<sub>i</sub>, dis<sub>i</sub>]</code> 表示一条连接 <code>u<sub>i</sub></code> 和 <code>v<sub>i</sub></code> ，距离为 <code>dis<sub>i</sub></code> 的边。注意，同一对节点间可能有<strong>多条</strong>边，且该图可能不是连通的。</p>

<p>实现 <code>DistanceLimitedPathsExist</code> 类：</p>

<ul>
	<li><code>DistanceLimitedPathsExist(int n, int[][] edgeList)</code> 以给定的无向图初始化对象。</li>
	<li><code>boolean query(int p, int q, int limit)</code> 当存在一条从 <code>p</code> 到 <code>q</code> 的路径，且路径中每条边的距离都<strong>严格小于</strong> <code>limit</code> 时，返回 <code>true</code> ，否则返回 <code>false</code> 。</li>
</ul>

<p> </p>

<p><b>示例 1:</b></p>

<p><strong><img alt="" src="https://assets.leetcode.com/uploads/2021/01/05/messed.png" style="width: 300px; height: 298px;"></strong></p>

<pre><b>输入：</b>
["DistanceLimitedPathsExist", "query", "query", "query", "query"]
[[6, [[0, 2, 4], [0, 3, 2], [1, 2, 3], [2, 3, 1], [4, 5, 5]]], [2, 3, 2], [1, 3, 3], [2, 0, 3], [0, 5, 6]]
<b>输出：</b>
[null, true, false, true, false]

<b>解释：</b>
DistanceLimitedPathsExist distanceLimitedPathsExist = new DistanceLimitedPathsExist(6, [[0, 2, 4], [0, 3, 2], [1, 2, 3], [2, 3, 1], [4, 5, 5]]);
distanceLimitedPathsExist.query(2, 3, 2); // 返回 true。存在一条从 2 到 3 ，距离为 1 的边，
                                          // 这条边的距离小于 2。
distanceLimitedPathsExist.query(1, 3, 3); // 返回 false。从 1 到 3 之间不存在每条边的距离都
                                          // <strong>严格</strong>小于 3 的路径。
distanceLimitedPathsExist.query(2, 0, 3); // 返回 true。存在一条从 2 到 0 的路径，使得每条边的
                                          // 距离 &lt; 3：从 2 到 3 到 0 行进即可。
distanceLimitedPathsExist.query(0, 5, 6); // 返回 false。从 0 到 5 之间不存在路径。
</pre>

<p> </p>

<p><strong>提示：</strong></p>

<ul>
	<li><code>2 &lt;= n &lt;= 10<sup>4</sup></code></li>
	<li><code>0 &lt;= edgeList.length &lt;= 10<sup>4</sup></code></li>
	<li><code>edgeList[i].length == 3</code></li>
	<li><code>0 &lt;= u<sub>i</sub>, v<sub>i</sub>, p, q &lt;= n-1</code></li>
	<li><code>u<sub>i</sub> != v<sub>i</sub></code></li>
	<li><code>p != q</code></li>
	<li><code>1 &lt;= dis<sub>i</sub>, limit &lt;= 10<sup>9</sup></code></li>
	<li>最多调用 <code>10<sup>4</sup></code> 次 <code>query</code> 。</li>
</ul>
































# 解题:
# 1.O(mlogm)-O(α(n)loglogn)/O(logn) 的可持久化并查集解法
这道题是 [1697. 检查边长度限制的路径是否存在](/problems/checking-existence-of-edge-length-limited-paths/) 的加强版本，两道题要计算的结果没有任何区别，唯一的区别是 $1697$ 题的查询是一次性给出的（离线查询），而这道题是通过查询函数分多次给出（在线查询）。

### 离线版本的解法
对于离线查询，可以随意地调整处理查询地顺序，降低问题的难度。

$1697$ 题的标准解法正是通过对查询按限制 $limit$ 排序，排序后，查询时可用的边的数量是单调不减的，因此可以随着查询的进行，把边逐渐添加到图中，并用并查集维护图的连通性。

### 离线版本与在线版本的区别
把离线版本问题的解决思路应用到在线版本有哪些困难？

主要差别在于离线版本具有单调性，边只会增加而不会减少，虽然一次查询中可能添加多条边，但每条边只会被添加一次，因此用并查集维护连通性的成本很低。

而在线版本的查询不具有单调性，边可能增加，可能减少，两次相邻查询之间，可用边的差距可能非常大。

### 离线版本与在线版本的联系
经过对比可以发现，离线相比在线的主要优势在于可以调整查询顺序，使两次查询之间，问题的状态变化不会很大，可以简单地在上一次查询的基础上进行调整，快速得到本次查询地结果。

因此可以设想，如果能按照离线版本的顺序依次更新问题的状态，并将更新过程中的所有历史状态记录下来，然后在处理查询时，找到一个历史状态，与离线版本下处理到这个查询时的状态相同或相近，然后在这个历史状态下处理查询，就能达到与离线查询相似的效果了，这个思路就是**可持久化**。

### 可持久化
可持久化是针对数据结构而言的，可持久化数据结构可以在更新时保留这个数据结构的历史状态，并且可以在历史状态下进行查询。可持久化数据结构往往还可以在历史版本上更新，得到一个新版本，但这道题用不到这个性质。

实现可持久化的重要思想是共享。数据结构在更新时往往只有一小部分会发生变化，于是剩下的未发生改变的部分可以在不同版本之间共享，只有发生改变的那一小部分需要新建，并查集是符合这一特征的，可以进行可持久化。

### 第一种可持久化思路
对于只实现在最新版本上更新和在历史版本上查询这两个操作的简化版可持久化数据结构，$\text{leetcode}$ 上有一道例题 [1146. 快照数组](/problems/snapshot-array/)，并查集可以用数组实现，因此 $1146$ 题的方法可以完全照搬到本题。

实现方法很简单，给数组的每一个值额外附加一个版本号，数组的同一个位置可以有多个版本不同的值。数组的每个值更新时，就在这个位置添加一个新版本的值；查询时，由于版本号单调递增，因此可以二分查找小于等于查询版本的最新版本，这个版本对应的值就是查询版本下的值。

对数组实现了可持久化之后，只要在可持久化数组上实现并查集，就得到了可持久化并查集，路径压缩和启发式合并等并查集优化也都可以用。

### 第二种可持久化思路
第一种可持久化思路是直接在可持久化数组上建立并查集，可持久化数组的每个点可以发生多次改变，因此需要记录多个不同版本的值。

但在不采用路径压缩优化的情况下，并查集每个点只会发生一次改变，这种情况下可以只记录最新版本的值，查询时只需要忽略高版本的值即可。

### 解题思路
初始化时，对所有边按距离排序，从小到大用每一条边对可持久化并查集进行更新。

查询时，用二分查找找到不包含距离大于限制值 $limit$ 的边的最新版本，在该版本上进行查询。

并且可以注意到，可持久化数组并不要求版本号连续，因此在这道题中，可以直接用边的距离作为版本号。

### 复杂度分析
设 $n$ 为点的数量，$m$ 为边的数量。

先分析第一种可持久化思路的时间复杂度。

初始化时，只需要在最新版本上更新，因此查询时可以直接用最新版本的值，不用二分查找，时间复杂度包括排序的 $O(m\log m)$ 和更新并查集的 $O(m\alpha(n))$，总时间复杂度为 $O(m\log m)$。

每次查询时，需要查找 $O(\alpha(n))$ 个并查集的值，每次查找需要进行二分查找，二分查找的时间复杂度与每个点的版本数量相关，接下来分析版本数量的上限。

一个点发生更新有两种情况：
- 一是连通分量的大小发生变化，根节点的大小需要发生改变。连通分量的大小信息只在并查集更新时有用，查询时就用不到了，而初始化时并查集只需要用到最新版本的值，因此更新时可以不添加新的版本，而是在原来的版本上直接修改大小信息。
- 二是节点的父节点发生改变。除了第一次连接到新的连通分量以外，这个改变只会在路径压缩时发生，由于路径压缩后节点的深度固定变为 $2$，节点深度变为 $2$ 以后路径就不可压缩了，只有当节点的深度再次增加到 $2$ 以上，才有可能再次发生压缩，而节点深度增加只会在当前连通分量连接到另一个连通分量时发生。由于使用了启发式合并，连接到的连通分量一定比当前连通分量大，因此连接后连通分量大小至少翻倍，由此可得，一个节点的深度增加最多发生 $\lfloor\log_2n\rfloor$ 次。

根据上面的分析可知，一个点最多有 $O(\log n)$ 个版本的值，因此一次二分查找的时间复杂度是 $O(\log\log n)$ 的，一次查询的总时间复杂度为 $O(\alpha(n)\log\log n)$。

空间复杂度主要为可持久化并查集的空间，可持久化并查集初始有 $n$ 个值，每次更新最多增加 $O(\alpha(n))$ 个值，总共需要更新 $m$ 次，因此总空间复杂度为 $O(n+m\alpha(n))$。

然后是第二种可持久化思路的复杂度，第二种可持久化思路的复杂度好分析些。

初始化复杂度包括排序的 $O(m\log m)$ 和更新并查集的 $O(m\log n)$，初始化的总时间复杂度为 $O(m\log m)$。

每次查询时，需要两次并查集查询，时间复杂度为 $O(\log n)$。

空间复杂度为并查集的 $O(n)$。

### 代码
```cpp []
template<typename G, typename S>
int find(G&& getter, S&& setter, int x) {
    const int sx = getter(x);
    if (sx < 0) return x;
    const int fx = find(getter, setter, sx);
    setter(x, fx);
    return fx;
}

template<typename G, typename S>
bool merge(G&& getter, S&& setter, int x, int y) {
    int fx = find(getter, setter, x);
    int fy = find(getter, setter, y);
    if (fx == fy) return false;
    const int sx = getter(fx);
    const int sy = getter(fy);
    if (sx < sy) swap(fx, fy);
    setter(fy, sx + sy);
    setter(fx, fy);
    return true;
}

class DistanceLimitedPathsExist {
public:
    struct Node {
        int parent;
        int version;
    };

    vector<vector<Node>> ufs;

    DistanceLimitedPathsExist(int n, vector<vector<int>>& edgeList)
        : ufs(n, vector<Node>{{-1, 0}}) {
        sort(edgeList.begin(), edgeList.end(),
            [] (const vector<int>& x, const vector<int>& y) {
                return x[2] < y[2];
            }
        );
        for (const auto& e : edgeList) {
            const int d = e[2];
            merge(
                [this] (int p) {
                    return ufs[p].back().parent;
                },
                [this, d] (int p, int v) {
                    auto& ref = ufs[p];
                    auto& val = ref.back();
                    if (v < 0 || val.version == d)
                        val.parent = v;
                    else if (val.parent != v)
                        ref.push_back({v, d});
                },
                e[0],
                e[1]
            );
        }
    }
    
    bool query(int p, int q, int limit) const {
        const auto f = [=] (int p) {
            return find(
                [=] (int p) {
                    return prev(
                        partition_point(ufs[p].begin(), ufs[p].end(), 
                            [=] (const Node& x) {
                                return x.version < limit;
                            }
                        )
                    )->parent;
                },
                [=] (int p, int v) {},
                p
            );
        };
        return f(p) == f(q);
    }
};
```
```cpp []
class DistanceLimitedPathsExist {
public:
    struct Node {
        int limit;
        int parent;
    };

    vector<Node> ufs;

    static int find(vector<Node>& ufs, int x) {
        while (0 <= ufs[x].parent)
            x = ufs[x].parent;
        return x;
    }

    static int find(vector<Node>& ufs, int x, int lim) {
        while (0 <= ufs[x].parent && ufs[x].limit < lim)
            x = ufs[x].parent;
        return x;
    }

    static bool merge(vector<Node>& ufs, int x, int y, int lim) {
        int fx = find(ufs, x);
        int fy = find(ufs, y);
        if (fx == fy) return false;
        const int sx = ufs[fx].parent;
        const int sy = ufs[fy].parent;
        if (sx < sy) swap(fx, fy);
        ufs[fy].parent = sx + sy;
        ufs[fx].parent = fy;
        ufs[fx].limit = lim;
        return true;
    }

    DistanceLimitedPathsExist(int n, vector<vector<int>>& edgeList)
        : ufs(n, {0, -1}) {
        sort(edgeList.begin(), edgeList.end(),
            [] (const vector<int>& x, const vector<int>& y) {
                return x[2] < y[2];
            }
        );
        for (const auto& e : edgeList)
            merge(ufs, e[0], e[1], e[2]);
    }
    
    bool query(int p, int q, int limit) {
        return find(ufs, p, limit) == find(ufs, q, limit);
    }
};
```
# 2.可持久化并查集
### 解题思路
#### 初始化
先将所有边升序排列，从小到大依次合并并查集，每次合并时，记录连接的边的权值（时间戳）
#### 查询
查找公共祖先时，时间戳必须严格小于 `limit` 时，才能向祖先移动

显然，由于连接边带有时间戳信息，不能进行路径压缩，只能使用按秩合并来进行优化

### 代码

```python
inf = sys.maxsize
class DistanceLimitedPathsExist:
    def find(self, i, mt=inf):
        return i if i == self.f[i] or self.t[i] >= mt else self.find(self.f[i], mt)
    
    def union(self, i, j, t):
        fi, fj = self.find(i), self.find(j)
        if fi != fj:
            if self.m[fj] > self.m[fi]:
                self.t[fi] = t
                self.f[fi] = fj
            else:
                self.t[fj] = t
                self.f[fj] = fi
            if self.m[fi] == self.m[fj]:
                self.m[fi] += 1

    def __init__(self, n: int, edgeList: List[List[int]]):
        edgeList.sort(key=lambda it:it[2])
        f = list(range(n)) # 集合的根
        m = [0] * n # 树的深度
        t = [inf - 1] * n # 合并的时间戳
        self.f = f
        self.m = m
        self.t = t
        for u, v, t in edgeList:
            self.union(u, v, t)

    def query(self, p: int, q: int, limit: int) -> bool:
        return self.find(p, limit) == self.find(q, limit)
```
# 3.Python3 Kruskal + 倍增LCA
## 前言

本题为 [LC1697](https://leetcode-cn.com/problems/checking-existence-of-edge-length-limited-paths/) 的在线版本。
 
相关题解：[离线版本](https://leetcode-cn.com/problems/checking-existence-of-edge-length-limited-paths/solution/jian-cha-bian-chang-du-xian-zhi-de-lu-ji-c756/) by [@zerotrac2](/u/zerotrac2/), [在线版本](https://leetcode-cn.com/problems/checking-existence-of-edge-length-limited-paths/solution/zai-xian-zuo-fa-shu-shang-bei-zeng-lca-b-lzjq/) by [@cwolf9](/u/cwolf9/) （与本文思路一致）

对于离线版本，我们将所有 `query` 按照权重排序，每次 `query` 之前保证所有严格小于该权重的边全部添加即可。

## 思路

首先可以证明，对于任意两点 `u`, `v`, **最小生成树**上的路径一定是它们之间最大边权最小的路径。（考虑 Kruskal 算法，加边是按照边权**从小到大**添加）

那么问题就变成了求两个点在最小生成树上路径的最大边权。对于任意一棵树，我们可以人为定义一个根，显然这个路径会经过两点的**最近公共祖先** `LCA(u, v)`, 那么这个路径就变成 `u -- LCA(u, v) -- v`, 也就是 `u -- LCA + v -- LCA`.

那么，对于每一个 `query`, 问题就变成了求出这两个点在最小生成树上的最近公共祖先，而在求解的同时，我们要维护路径中的最大边权，并在最后与阈值判断。

### 求解 LCA

最朴素的（非递归）算法是，先让深度较大的点向上跳以对齐两点深度，然后两点一起向上跳，时间复杂度为 $O(n)$, 显然不够优秀，在本题可能介于超时和通过之间（`Python` `10**8` 基本没救了）。

实际上，我们可以通过将深度进行**二进制拆分**来优化跳转的过程。

对于每个点，我们首先用一遍 DFS 遍历出每个节点的深度，父节点和到父节点边的边权，进而可以**预处理**出其第 `2**k` 个祖先（父节点为 `2**0 = 1`），方法类似于快速幂（[LC 50](https://leetcode-cn.com/problems/powx-n/)）。在处理的同时，我们也可以维护点与这些祖先路径上的最大边权。

这样优化后，在第一步中，我们将深度差 `d` 进行二进制拆分，使其转化为 `d` 的二进制表示中所含 `1` 的个数次跳转；在第二步中，我们从最大的 `k` 开始循环尝试，一直到 `0` （包括 `0`），如果该 `k` 值时两点的对应祖先不相同，那么进行跳转。最后的 LCA 就是最终任意一点的父节点。

预处理过程代码：
```python3
# init LCA
for i in range(1, 15): # 2 ** 14 = 16384 > 10 ** 4
    for u in range(n):
        self.pa[u][i] = self.pa[self.pa[u][i-1]][i-1]
        self.mw[u][i] = max(self.mw[u][i-1], self.mw[self.pa[u][i-1]][i-1])
```


求解 LCA 的过程代码：
```python3
# LCA query: return max weight
def _lca(self, u: int, v: int) -> int:
    if self.dep[u] > self.dep[v]:
        u, v = v, u
    # step 1: align to the same height
    tmp = self.dep[v] - self.dep[u]
    res = 0 # maximum weight in path
    i = 0
    while tmp:
        if tmp & 1:
            res = max(res, self.mw[v][i])
            v = self.pa[v][i]
        tmp >>= 1
        i += 1
    if u == v:
        return res
    # step 2: skip to lca
    for i in range(14, -1, -1):
        if (self.pa[v][i] != self.pa[u][i]):
            res = max(res, self.mw[u][i], self.mw[v][i])
            v = self.pa[v][i]
            u = self.pa[u][i]
    res = max(res, self.mw[u][0], self.mw[v][0])
    return res
```


## 代码

- 预处理
    - Kruskal 生成最小生成树（森林）
    - 对森林进行 DFS 求出每个点 `u` 的深度 `dep[u]`, 父节点 `pa[u][0]` 和到父节点边的边权 `mw[u][0]`.
    - 预处理生成每个点的第 `2**k` 代祖先 `pa[u][k]` 和到该点路径的最大边权 `mw[u][k]`.
- 查询（LCA）
    - 判断两点是否连通，若不连通直接返回 `False`
    - 首先将两个点对齐到同一深度
    - 循环尝试找到它们的 LCA
    - 在过程中更新最大边权，最后与阈值判断
```python3
class DSU:
    
    def __init__(self, n):
        self.count = [1] * n 
        self.parent = [_ for _ in range(n)]

    def find(self, i): # find root(i) and compress the path
        if self.parent[i] != i:
            self.parent[i] = self.find(self.parent[i])
        return self.parent[i]

    def union(self, i, j): # return if already connected
        pi, pj = self.find(i), self.find(j)
        if pi != pj:
            if self.count[pi] < self.count[pj]:
                pi, pj = pj, pi
            self.parent[pj] = pi
            self.count[pi] += self.count[pj]
            return False
        return True
    
class DistanceLimitedPathsExist:

    def __init__(self, n: int, edgeList: List[List[int]]):
        self.n = n
        self.dsu = DSU(n)
        self.edges = sorted(edgeList, key = lambda x: x[2]) # original edges
        self.medges = [dict() for _ in range(n)] # edges in mst
        self.pa = [[-1] * 15 for _ in range(n)] # 2 ** k-th parent in mst
        self.mw = [[0] * 15 for _ in range(n)] # maximum weight to 2 ** k-th parent
        self.dep = [0] * n # depth of nodes in mst
        self._vis = [False] * n
        # kruskal
        self._kruskal()
        # dfs
        for i in range(n):
            if self._vis[i] is False:
                self.dep[i] = 1
                self._dfs(i)
                self.pa[i][0] = i
        # init LCA
        for i in range(1, 15):
            for u in range(n):
                self.pa[u][i] = self.pa[self.pa[u][i-1]][i-1]
                self.mw[u][i] = max(self.mw[u][i-1], self.mw[self.pa[u][i-1]][i-1])
        # debug
        # print(self.medges)
        # print(self.pa)
        # print(self.mw)
    
    def _dfs(self, u):
        self._vis[u] = True
        for v, w in self.medges[u].items():
            if self._vis[v]:
                continue
            self.dep[v] = self.dep[u] + 1
            self.pa[v][0] = u
            self.mw[v][0] = w
            self._dfs(v)
            
    
    def _kruskal(self):
        for u, v, w in self.edges:
            if self.dsu.union(u, v) is False: # edge in mst
                self.medges[u][v] = w
                self.medges[v][u] = w
        
    
    # LCA query: return max weight
    def _lca(self, u: int, v: int) -> int:
        if self.dep[u] > self.dep[v]:
            u, v = v, u
        # align to the same height
        tmp = self.dep[v] - self.dep[u]
        res = 0 # maximum weight in path
        i = 0
        while tmp:
            if tmp & 1:
                res = max(res, self.mw[v][i])
                v = self.pa[v][i]
            tmp >>= 1
            i += 1
        if u == v:
            return res
        # skip to lca
        for i in range(14, -1, -1):
            if (self.pa[v][i] != self.pa[u][i]):
                res = max(res, self.mw[u][i], self.mw[v][i])
                v = self.pa[v][i]
                u = self.pa[u][i]
        res = max(res, self.mw[u][0], self.mw[v][0])
        return res
    
    def query(self, p: int, q: int, limit: int) -> bool:
        if self.dsu.find(p) != self.dsu.find(q): # not connected
            return False
        return self._lca(p, q) < limit



# Your DistanceLimitedPathsExist object will be instantiated and called as such:
# obj = DistanceLimitedPathsExist(n, edgeList)
# param_1 = obj.query(p,q,limit)
```


## 复杂度分析

- 时间复杂度：$O(m\log m + n + q\log n)$. 
    - 预处理时， Kruskal 算法的复杂度是 $O(m\log m)$, 遍历最小生成森林的复杂度是 $O(n)$, 预处理 LCA 的复杂度是 $O(n\log n)$. 
    - 对于单个 `query`, 求解 LCA 的时间复杂度为 $O(\log n)$.
- 空间复杂度：$O(n\log n + \log m)$. 其中排序 `edgeList` 的栈空间为 $O(\log m)$, 并查集为 $O(n)$, 预处理的祖先和最大边权数组为 $O(n\log n)$.



## 相关题目

- [LC 1483](https://leetcode-cn.com/problems/kth-ancestor-of-a-tree-node/). 树上倍增模板题（

- [NOIP2013 提高组] 货车运输，[洛谷 P1967](https://www.luogu.com.cn/problem/P1967). 这道题仅仅将本题求解最大边权的最小值变为求解最小边权的最大值。

- 并查集的应用 B, [OI-Wiki](https://oi-wiki.org/topic/dsu-app/#b).

## 相关资料

- 最近公共祖先 - 倍增算法，[OI-Wiki](https://oi-wiki.org/graph/lca/#_5).

- 最小生成树 - Kruskal 算法，[OI-Wiki](https://oi-wiki.org/graph/mst/#kruskal).

- 半小时搞定 LCA 问题，[bilibili](https://www.bilibili.com/video/BV1W5411x7Fp).
# 4.Java双百 构建并查集同时记录并查集连线时间
### 解题思路
dsu[*][1] 存储第一次连上两个分量的时间， 在查询的时候只走时间戳严格小于limit的并查集路径即可

### 代码

```java
class DistanceLimitedPathsExist {
    int[][] dsu;
    public DistanceLimitedPathsExist(int n, int[][] edgeList) {
        dsu = new int[n][2];
        int[][] tmp = dsu;
        for(int i=0;i<n;i++){
            dsu[i][0] = i;
            dsu[i][1] = 0;
        }
        Arrays.sort(edgeList, (a,b)->a[2]-b[2]);
        for(int[] edge:edgeList){
            int a = edge[0];
            int b = edge[1];
            while(dsu[a][0]!=a){
                a = dsu[a][0];
            }
            while(dsu[b][0]!=b){
                b = dsu[b][0];
            }
            if(a!=b){
                dsu[a][0] = b;
                dsu[a][1] = edge[2];
            }
        }
    }
    
    public boolean query(int p, int q, int limit) {
            int[][] tmp = dsu;
            int a = p;
            int b = q;
            while(dsu[a][0]!=a&&dsu[a][1]<limit){
                a = dsu[a][0];
            }
            while(dsu[b][0]!=b&&dsu[b][1]<limit){
                b = dsu[b][0];
            }
            return a==b;
    }
}

/**
 * Your DistanceLimitedPathsExist object will be instantiated and called as such:
 * DistanceLimitedPathsExist obj = new DistanceLimitedPathsExist(n, edgeList);
 * boolean param_1 = obj.query(p,q,limit);
 */
```
